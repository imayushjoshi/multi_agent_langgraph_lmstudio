{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ab9011-a03e-4560-9813-214606184bcc",
   "metadata": {},
   "source": [
    "# Creation of VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dccb6e4-01ca-46a6-9d23-533edbdc9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec70a4ff-a08c-4215-890a-f930fcc1449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"ICICI Securities-13.08.2024.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74096237-13d3-4f1e-9aa4-3cd0dc88ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=3500, chunk_overlap=350)\n",
    "docs = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e21ee998-6214-4bf3-8ebf-faea68710006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qy/016_ccsd2jv3fyqdwn79s38w0000gn/T/ipykernel_4723/4178953686.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"jinaai/jina-embeddings-v2-base-en\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b69cae-6578-4f64-96a6-0ba2b90ca8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qy/016_ccsd2jv3fyqdwn79s38w0000gn/T/ipykernel_4723/2870945168.py:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  vectorstore=Chroma(collection_name=folder,persist_directory=persistant_directory,embedding_function=embeddings)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "folder=\"ICICI_vectorstore_3500_350\"\n",
    "persistant_directory=\"/Users/imayu/Desktop/Coding Projects/equity research report multi agent langgraph/\"+folder+\"/\"\n",
    "vectorstore=Chroma(collection_name=folder,persist_directory=persistant_directory,embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f9cec6-8654-44f6-9cd3-2f60d944f0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2ca6f8b0-b131-4e41-9074-cb25beb32003',\n",
       " '0e764e20-bf09-4a3b-85e2-f7ab4281762d',\n",
       " '4b6945ad-0b05-4463-bf38-b8800aa902e8',\n",
       " '0a5603ce-e3f6-4b40-88e8-28c4af869c3e',\n",
       " 'a79a74b7-6f7c-4357-96ab-09bff4294212',\n",
       " '344f962a-a4e2-4092-921c-b7417dc756f7',\n",
       " 'e3d30756-8f65-44fb-9fd3-b030519f1283',\n",
       " '69a61157-11e7-413b-858f-aa2af9cdf04a',\n",
       " '9943fc5b-b98e-4e13-b7f9-8aea85416d11',\n",
       " 'dbaaf0df-7b01-42d1-b58e-4e77b793bf43',\n",
       " 'edd1bc21-82a4-4569-b7a9-8c6e2c084587',\n",
       " 'a53c8e8b-dc9a-47d7-9719-47f8d277d2cf',\n",
       " '0a8033cc-14a8-4059-8da5-cee71032468c',\n",
       " '2eb4d844-ba8b-47de-83df-752549aeb595',\n",
       " 'da8fd7be-5ea8-4d91-9039-e6e77371a4a1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c51339-83a5-46d1-8f09-6eacb9afd770",
   "metadata": {},
   "source": [
    "# Loading an exisiting vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "850b1f68-f05d-41f3-8e65-0f11d69c458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "vectorstore_directory=\"/Users/imayu/Desktop/Coding Projects/equity research report multi agent langgraph/ICICI_vectorstore\"\n",
    "CHROMA_COLLECTION=\"ICICI_vectorstore\"\n",
    "client=chromadb.Client(Settings(is_persistent=True,persist_directory=vectorstore_directory))\n",
    "collection=client.get_collection(name=CHROMA_COLLECTION)\n",
    "all_items=collection.get(include=[\"metadatas\",\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004103ca-c4ca-4188-8c51-62f35ff8a92d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
